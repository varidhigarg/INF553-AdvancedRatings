{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load predict topic model\n",
    "import predict_topic\n",
    "predict_topic.init('nmf_model.joblib', 'vectorizer.joblib')\n",
    "\n",
    "# load predict sentiment model\n",
    "import predict_sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data and set #data\n",
    "total_data= 200000\n",
    "data_filename= 'restaurant_review.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# returns topic and sentiment dictionary {D[topic#]['SA'] = #} per review\n",
    "def rating_per_review(review):\n",
    "    #print review\n",
    "    d = {}\n",
    "    i = 0\n",
    "    for sentence in review.split(\".\"):\n",
    "        SA = predict_sentiment.get_sentiment(sentence)[0]\n",
    "        i += 1\n",
    "        topic = predict_topic.predict_topic(sentence)\n",
    "        d[topic] = d.get(topic,{})\n",
    "        d[topic][SA] = d[topic].get(SA,0)\n",
    "        d[topic][SA] += 1   \n",
    "    return d    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for given data, returns average rating of a business considering both topic and sentiment analysis\n",
    "def rating_per_business(documents):\n",
    "    #{ i : 0 for i in range(4) }\n",
    "    final_d = {}\n",
    "    aggregate_rating = { i : 0.0 for i in range(5) }\n",
    "    for review in documents:\n",
    "        r = rating_per_review(review[\"text\"])\n",
    "        advanced_r = r\n",
    "        \n",
    "        # combine ratings for all reviews of a business\n",
    "        for topic in r:\n",
    "            final_d[topic] = final_d.get(topic,{})           \n",
    "            for SA in r[topic]:  \n",
    "                final_d[topic][SA] = final_d[topic].get(SA,0)\n",
    "                final_d[topic][SA] += r[topic][SA]\n",
    "    \n",
    "    # find the average SA per topic (P / P + N)\n",
    "    for topic in final_d:\n",
    "               # print d[topic]\n",
    "            positive = final_d[topic]['P'] if 'P' in final_d[topic] else 0\n",
    "            negative = final_d[topic]['N'] if 'N' in final_d[topic] else 0\n",
    "\n",
    "            aggregate_rating[topic] = (positive*1.0)/(positive+ negative)*1.0\n",
    "    # return aggregate rating for entire business\n",
    "    # {0: 1.0, 1: 0.8571428571428571, 2: 0.0, 3: 1.0, 4: 0.0}\n",
    "    return aggregate_rating  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "with open(data_filename) as f:\n",
    "        head = [json.loads(next(f)) for x in range(total_data)]\n",
    "        \n",
    "businesses = {}\n",
    "users = {}\n",
    "users_business_topic_rating =defaultdict(list)\n",
    "business_id_map ={}\n",
    "id_business_map ={}\n",
    "count_business = 0\n",
    "count_user = 0\n",
    "user_id_map = {}\n",
    "id_user_map = {}\n",
    "\n",
    "\n",
    "# loop through each review in the data\n",
    "for i in head:\n",
    "    b_id = i[\"business_id\"]\n",
    "    # create business->id and id->business map\n",
    "    if b_id not in business_id_map:\n",
    "        business_id_map[b_id] = count_business \n",
    "        id_business_map[count_business] = b_id\n",
    "        count_business += 1\n",
    "    # businesses contains all the reviews for a given business\n",
    "    # each businesses[b_id] will have an array of reviews for that particular b_id\n",
    "    businesses[b_id] = businesses.get(b_id, [])\n",
    "    businesses[b_id].append(i)\n",
    "    \n",
    "    # create user->id and id->user map\n",
    "    u_id = i[\"user_id\"]\n",
    "    if u_id not in user_id_map:\n",
    "        user_id_map[u_id] = count_user \n",
    "        id_user_map[count_user] = u_id\n",
    "        count_user += 1\n",
    "    # users contains all the reviews given by a user\n",
    "    # each users[u_id] will have an array of reviews given by that particular u_id\n",
    "    users[u_id] = users.get(u_id, [])\n",
    "    users[u_id].append(i)\n",
    "    text = i[\"text\"]\n",
    "    \n",
    "    # for each review, get the average rating per topic (based on sentiment analysis)\n",
    "    rating_for_topic = rating_per_business([i])\n",
    "    # loop through topics of the particular review\n",
    "    for topic in rating_for_topic:\n",
    "        # store per topic rating separately, topic: [[user, business, rating]]\n",
    "        # {0: [[0, 0, 0.5],\n",
    "        #      [0, 1, 1.0]...\n",
    "        users_business_topic_rating[topic].append([user_id_map[u_id],business_id_map[b_id],rating_for_topic[topic]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
   ],
   "source": [
    "#users_business_topic_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
   ],
   "source": [
    "# get average rating per user\n",
    "users_rating_per_topic = defaultdict(dict)\n",
    "for x in users:\n",
    "    users_rating_per_topic[x] =   rating_per_business(users[x])\n",
    "    print (x,users_rating_per_topic[x] )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext(\"local\", \"Recommend\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model per topic\n",
    "from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating\n",
    "rank = 10\n",
    "numIterations = 10\n",
    "topic_model = {}\n",
    "# train each model using topic-specific data and store in topic_model\n",
    "for topic in range(5):\n",
    "    ratings = users_business_topic_rating[topic][:140000]\n",
    "    ratings = sc.parallelize(ratings)\n",
    "    model = ALS.train(ratings, rank, numIterations)\n",
    "    topic_model[topic] = model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error = 0.016426485424\n",
      "Mean Squared Error = 0.069038751528\n",
      "Mean Squared Error = 0.095547248426\n",
      "Mean Squared Error = 0.071963895695\n",
      "Mean Squared Error = 0.0\n"
     ]
    }
   ],
   "source": [
    "# compute MSE per topic\n",
    "for topic in range(5):\n",
    "    # retrieve test data for the topic\n",
    "    test_ratings = users_business_topic_rating[topic][1200:]\n",
    "    test_ratings = sc.parallelize(test_ratings)\n",
    "    # format testdata to get (user_id, business_id)\n",
    "    testdata = test_ratings.map(lambda x: (x[0], x[1]))\n",
    "    # retrieve topic specific trained model\n",
    "    model = topic_model[topic]\n",
    "    # predict\n",
    "    predictions = model.predictAll(testdata).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "    ratesAndPreds = test_ratings.map(lambda r: ((r[0], r[1]), r[2])).leftOuterJoin(predictions)\n",
    "    # take the average rating of a user in case there is no prediction (when the user has not been seen in the training data)\n",
    "    ratesAndPreds =ratesAndPreds.map(lambda r:((r[0][0], r[0][1]), (r[1][0],r[1][1] or users_rating_per_topic[id_user_map[r[0][0]]][topic]) ))\n",
    "    # calculate MSE\n",
    "    MSE = (ratesAndPreds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "    print(\"Mean Squared Error = \" + str(MSE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qI9WTIXOi2OTSG4bsc55fw\n"
     ]
    }
   ],
   "source": [
    "# predict for specific existing user\n",
    "\n",
    "import operator\n",
    "new_user = 'qI9WTIXOi2OTSG4bsc55fw'\n",
    "print(new_user)\n",
    "avg_topic_rating_for_user = users_rating_per_topic[new_user]\n",
    "selected_topic = max(avg_topic_rating_for_user.iteritems(), key=operator.itemgetter(1))[0]\n",
    "# select model based on average rating of user (aka which topic the user prefers the most)\n",
    "selected_model = topic_model[selected_topic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rate all businesses using above model and pick top 10\n",
    "\n",
    "test_data_for_selected_user = []\n",
    "\n",
    "for business in id_business_map:\n",
    "    test_data_for_selected_user.append((user_id_map[new_user], business))\n",
    "test_data_for_selected_user = sc.parallelize(test_data_for_selected_user)\n",
    "predictions = selected_model.predictAll(test_data_for_selected_user)#.map(lambda r: ((r[0], r[1]), r[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
   ],
   "source": [
    "# sort predictions\n",
    "sorted_predictions = sorted(predictions.collect(),key = lambda x: x[1], reverse = True)\n",
    "sorted_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
   ],
   "source": [
    "# predict top 10\n",
    "for x in sorted_predictions[:10]:\n",
    "    print (id_user_map[x[0]],id_business_map[x[1]], x[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
